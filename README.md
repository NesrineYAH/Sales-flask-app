ğŸ›ï¸ Analyse des ventes dâ€™une PME â€” Projet Data Engineer
ğŸ¯ Objectif

Ce projet a pour but de mettre en place une architecture conteneurisÃ©e (via Docker) pour :

Importer et structurer des donnÃ©es issues de fichiers CSV (produits, ventes, magasins).

Construire une base SQLite adaptÃ©e Ã  lâ€™analyse des ventes.

Offrir une interface web Flask avec affichage des donnÃ©es et graphiques HTML.

RÃ©aliser des premiÃ¨res analyses exploratoires en SQL et Python.

Mettre en place un pipeline ETL automatisÃ© avec logs pour suivre lâ€™intÃ©gritÃ© et les totaux des ventes.


<H2>ğŸ—‚ï¸ Structure du projet</H2>
<img src="./image_Structure_Projet.png" alt="struture projet">

<H2>ğŸ“Š DonnÃ©es utilisÃ©es </h2> 
<ul>
<li>products.csv â†’ informations sur les produits (ID, nom, prix, stock)</li>
<li>stores.csv â†’ informations sur les magasins (ID, ville, nombre de salariÃ©s)</li>
<li>sales.csv â†’ Toutes les ventes (ID produit, quantitÃ©, magasin, date)</li>
<li>ventes_jours.csv â†’affiche  ventes journaliÃ¨res par jours (ID produit, quantitÃ©, magasin, date)</li>
</ul>

<H2>Base de donnÃ©es </h2> 
<ul>
<li>produits (ID_produit, nom, prix, stock)</li>
<li>magasins (ID_magasin, ville, nombre_salaries)</li>
<li>ventes (ID_vente, ID_produit, ID_magasin, date, quantite, total_price)</li>
<li>Mise Ã  jours ventes de chaque jour</li>
</ul>
<p>La base SQLite est crÃ©Ã©e automatiquement via init_db.py et importÃ©e depuis les fichiers CSV. </p>

<H2> âš™ï¸ Pipeline ETL </h2> 
<ul>
<li>1.Lecture du fichier CSV (ventes_jour.csv ou fichier test).</li>
<li>2.Insertion des ventes dans la table ventes.</li>
<li>3.Calcul du total des ventes par produit (quantite * prix).</li>
<li>3.Mise Ã  jour de la colonne total_price dans la base.</li>
<li>4.VÃ©rification de lâ€™intÃ©gritÃ© des donnÃ©es (pas de produits inexistants).</li>
<li>5.VÃ©rification de lâ€™intÃ©gritÃ© des donnÃ©es (pas de produits inexistants).</li>
<li>5.Ã‰criture des logs dans logs/etl.log avec horodatage et succÃ¨s/erreur.</li>
</ul>


<H2>Lancer manuellement le pipeline </H2>
<strong> python run_etl.py </strong>
<ul>
<li>Le fichier etl.log sera crÃ©Ã© automatiquement si le dossier logs/ existe.</li>
<li> Les messages typiques dans le log :</li>
</ul> 
<img src="./console_Termianl.png"  alt ="consol de logs terminal" />

<H2>Automatisation quotidienne (optionnelle) </H2>
Via schedule.py et la variable .env :
<img src="./Schedule.png"  alt ="<img src="./Schedule.png"  alt ="" />
 />

<H2>Automatisation quotidienne (optionnelle) </H2>
<H3> Construire et lancer avec Docker : </H3>

<img src="./docker compose.png"  alt ="docker   " />
<H3> Lancer l'application Flask  : </H3>
<img src="./python main.py.png"  alt ="python main" />

<H2>AccÃ©der Ã  lâ€™interface web :</H2> 
<ul> 
<li> Page dâ€™accueil : http://localhost:5000</li>
<li> Liste des produits : http://localhost:5000/produits <li>
<li>Liste des ventes : http://localhost:5000/ventes </li>
<li>Liste des magasins : http://localhost:5000/magasins </li>
<li>Statistiques et graphique : http://localhost:5000/stats</li>
</ul> 


<H2>ğŸ“ˆ Analyse et statistiques:</H2> 

<ul> 
<li>Total des ventes par produit </li>
<li>Chiffre dâ€™affaires global</li>
<li>Produit le plus vendu </li>
<li>Produit le plus vendu </li>
<li> PÃ©riode (mois) la plus active</li>
<li>Graphique des ventes par produit (Chart.js intÃ©grÃ© dans stats.html)</li>
</ul> 



<H2>ğŸ“ˆ ğŸ§° Technologies utilisÃ©es</H2> 

<ul> 
<li>Python (pandas, sqlite3, Flask) </li>
<li>Docker / Docker Compose</li>
<li>Chart.js pour visualisation des ventes </li>
<li>Produit le plus vendu </li>
<li> schedule pour automatisation du pipeline</li>
<li>logging pour suivi ETL</li>
</ul> 



